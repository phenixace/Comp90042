{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "from dataset import Dataset4SKEP\r\n",
    "import paddle\r\n",
    "from paddlenlp.datasets import MapDataset\r\n",
    "import paddle.nn as nn\r\n",
    "\r\n",
    "train_ds = Dataset4SKEP('train')\r\n",
    "train_ds = MapDataset(train_ds)\r\n",
    "dev_ds   = Dataset4SKEP('dev')\r\n",
    "dev_ds = MapDataset(dev_ds)\r\n",
    "test_ds  = Dataset4SKEP('test')\r\n",
    "test_ds = MapDataset(test_ds)\r\n",
    "print(train_ds[0:2])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "from paddlenlp.transformers import SkepForSequenceClassification, SkepTokenizer\r\n",
    "\r\n",
    "# load skep\r\n",
    "model = SkepForSequenceClassification.from_pretrained(pretrained_model_name_or_path=\"skep_ernie_2.0_large_en\", num_classes=2)\r\n",
    "# tokenizer loaded\r\n",
    "tokenizer = SkepTokenizer.from_pretrained(pretrained_model_name_or_path=\"skep_ernie_2.0_large_en\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001b[32m[2022-04-27 22:23:39,964] [    INFO]\u001b[0m - Already cached C:\\Users\\46901\\.paddlenlp\\models\\skep_ernie_2.0_large_en\\skep_ernie_2.0_large_en.pdparams\u001b[0m\n",
      "\u001b[32m[2022-04-27 22:23:46,342] [    INFO]\u001b[0m - Already cached C:\\Users\\46901\\.paddlenlp\\models\\skep_ernie_2.0_large_en\\skep_ernie_2.0_large_en.vocab.txt\u001b[0m\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "import os\r\n",
    "from functools import partial\r\n",
    "\r\n",
    "\r\n",
    "import numpy as np\r\n",
    "import paddle.nn.functional as F\r\n",
    "from paddlenlp.data import Stack, Tuple, Pad\r\n",
    "\r\n",
    "from utils import create_dataloader,convert_example\r\n",
    "\r\n",
    "\r\n",
    "batch_size = 4\r\n",
    "max_seq_length = 512\r\n",
    "\r\n",
    "trans_func = partial(\r\n",
    "    convert_example,\r\n",
    "    tokenizer=tokenizer,\r\n",
    "    max_seq_length=max_seq_length)\r\n",
    "\r\n",
    "batchify_fn = lambda samples, fn=Tuple(\r\n",
    "    Pad(axis=0, pad_val=tokenizer.pad_token_id),  # input_ids\r\n",
    "    Pad(axis=0, pad_val=tokenizer.pad_token_type_id),  # token_type_ids\r\n",
    "    Stack()  # labels\r\n",
    "): [data for data in fn(samples)]\r\n",
    "train_data_loader = create_dataloader(\r\n",
    "    train_ds,\r\n",
    "    mode='train',\r\n",
    "    batch_size=batch_size,\r\n",
    "    batchify_fn=batchify_fn,\r\n",
    "    trans_fn=trans_func)\r\n",
    "dev_data_loader = create_dataloader(\r\n",
    "    dev_ds,\r\n",
    "    mode='dev',\r\n",
    "    batch_size=batch_size,\r\n",
    "    batchify_fn=batchify_fn,\r\n",
    "    trans_fn=trans_func)\r\n",
    "\r\n",
    "\r\n",
    "import time\r\n",
    "\r\n",
    "from metrics import evaluate\r\n",
    "\r\n",
    "epochs = 10\r\n",
    "# save_dir\r\n",
    "ckpt_dir = \"skep_ckpt\"\r\n",
    "# step number\r\n",
    "num_training_steps = len(train_data_loader) * epochs\r\n",
    "\r\n",
    "optimizer = paddle.optimizer.AdamW(\r\n",
    "    learning_rate=5e-6,\r\n",
    "    parameters=model.parameters())\r\n",
    "criterion = paddle.nn.loss.CrossEntropyLoss()\r\n",
    "metric = paddle.metric.Accuracy()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "print('Total: ',num_training_steps)\r\n",
    "global_step = 0\r\n",
    "tic_train = time.time()\r\n",
    "for epoch in range(1, epochs + 1):\r\n",
    "    for step, batch in enumerate(train_data_loader, start=1):\r\n",
    "        input_ids, token_type_ids, labels = batch\r\n",
    "\r\n",
    "        logits = model(input_ids, token_type_ids)\r\n",
    "\r\n",
    "        loss = criterion(logits, labels)\r\n",
    "\r\n",
    "        probs = F.softmax(logits, axis=1)\r\n",
    "\r\n",
    "        correct = metric.compute(probs, labels)\r\n",
    "        metric.update(correct)\r\n",
    "        acc = metric.accumulate()\r\n",
    "\r\n",
    "        global_step += 1\r\n",
    "        if global_step % 200 == 0:\r\n",
    "            print(\r\n",
    "                \"global step %d, epoch: %d, batch: %d, loss: %.5f, accu: %.5f, speed: %.2f step/s\"\r\n",
    "                % (global_step, epoch, step, loss, acc,\r\n",
    "                    10 / (time.time() - tic_train)))\r\n",
    "            tic_train = time.time()\r\n",
    "\r\n",
    "        loss.backward()\r\n",
    "        optimizer.step()\r\n",
    "        optimizer.clear_grad()\r\n",
    "\r\n",
    "        if global_step % 200 == 0:\r\n",
    "            save_dir = os.path.join(ckpt_dir, \"model_%d\" % global_step)\r\n",
    "            if not os.path.exists(save_dir):\r\n",
    "                os.makedirs(save_dir)\r\n",
    "\r\n",
    "            evaluate(model, criterion, metric, dev_data_loader)\r\n",
    "\r\n",
    "            model.save_pretrained(save_dir)\r\n",
    "\r\n",
    "            tokenizer.save_pretrained(save_dir)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Total:  2270\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "OSError",
     "evalue": "(External)  Cublas error, `CUBLAS_STATUS_INTERNAL_ERROR`. An internal cuBLAS operation failed. This error is usually caused by a cudaMemcpyAsync() failure.  (at C:\\home\\workspace\\Paddle_release3\\paddle/fluid/operators/math/blas_impl.cu.h:35)\n",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-31c74ea3bb2d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     24\u001b[0m             \u001b[0mtic_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclear_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\decorator.py\u001b[0m in \u001b[0;36mfun\u001b[1;34m(*args, **kw)\u001b[0m\n\u001b[0;32m    229\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mkwsyntax\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    230\u001b[0m                 \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkw\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 231\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mcaller\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mextras\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    232\u001b[0m     \u001b[0mfun\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    233\u001b[0m     \u001b[0mfun\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\paddle\\fluid\\wrapped_decorator.py\u001b[0m in \u001b[0;36m__impl__\u001b[1;34m(func, *args, **kwargs)\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__impl__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[0mwrapped_func\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdecorator_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapped_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0m__impl__\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\paddle\\fluid\\framework.py\u001b[0m in \u001b[0;36m__impl__\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    225\u001b[0m         assert in_dygraph_mode(\n\u001b[0;32m    226\u001b[0m         ), \"We only support '%s()' in dynamic graph mode, please call 'paddle.disable_static()' to enter dynamic graph mode.\" % func.__name__\n\u001b[1;32m--> 227\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    228\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    229\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0m__impl__\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\paddle\\fluid\\dygraph\\varbase_patch_methods.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, grad_tensor, retain_graph)\u001b[0m\n\u001b[0;32m    236\u001b[0m                                           framework._dygraph_tracer())\n\u001b[0;32m    237\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 238\u001b[1;33m                 core.dygraph_run_backward([self], [grad_tensor], retain_graph,\n\u001b[0m\u001b[0;32m    239\u001b[0m                                           framework._dygraph_tracer())\n\u001b[0;32m    240\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: (External)  Cublas error, `CUBLAS_STATUS_INTERNAL_ERROR`. An internal cuBLAS operation failed. This error is usually caused by a cudaMemcpyAsync() failure.  (at C:\\home\\workspace\\Paddle_release3\\paddle/fluid/operators/math/blas_impl.cu.h:35)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "import numpy as np\r\n",
    "from utils import convert_example\r\n",
    "\r\n",
    "# process test data\r\n",
    "trans_func = partial(\r\n",
    "    convert_example,\r\n",
    "    tokenizer=tokenizer,\r\n",
    "    max_seq_length=max_seq_length,\r\n",
    "    is_test=True)\r\n",
    "batchify_fn = lambda samples, fn=Tuple(\r\n",
    "    Pad(axis=0, pad_val=tokenizer.pad_token_id),  # input\r\n",
    "    Pad(axis=0, pad_val=tokenizer.pad_token_type_id),  # segment\r\n",
    "    Stack() # qid\r\n",
    "): [data for data in fn(samples)]\r\n",
    "test_data_loader = create_dataloader(\r\n",
    "    test_ds,\r\n",
    "    mode='test',\r\n",
    "    batch_size=batch_size,\r\n",
    "    batchify_fn=batchify_fn,\r\n",
    "    trans_fn=trans_func)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# choose model directory\r\n",
    "params_path = './skep_ckpt/batch_size_4/model_500/model_state.pdparams'\r\n",
    "if params_path and os.path.isfile(params_path):\r\n",
    "    # load model\r\n",
    "    state_dict = paddle.load(params_path)\r\n",
    "    model.set_dict(state_dict)\r\n",
    "    print(\"Loaded parameters from %s\" % params_path)\r\n",
    "else:\r\n",
    "    print(\"Model not found\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Loaded parameters from ./skep_ckpt/batch_size_4/model_500/model_state.pdparams\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "label_map = {0 : 'nonrumour', 1 : 'rumour'}\r\n",
    "results = []\r\n",
    "\r\n",
    "model.eval()\r\n",
    "for batch in test_data_loader:\r\n",
    "    input_ids, token_type_ids, qids = batch\r\n",
    "\r\n",
    "    logits = model(input_ids, token_type_ids)\r\n",
    "    probs = F.softmax(logits, axis=-1)\r\n",
    "    idx = paddle.argmax(probs, axis=1).numpy()\r\n",
    "    idx = idx.tolist()\r\n",
    "    labels = [label_map[i] for i in idx]\r\n",
    "    qids = qids.numpy().tolist()\r\n",
    "    results.extend(zip(qids, labels))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "res_dir = \"./results\"\r\n",
    "if not os.path.exists(res_dir):\r\n",
    "    os.makedirs(res_dir)\r\n",
    "\r\n",
    "with open(os.path.join(res_dir, \"SKEP.csv\"), 'w+', encoding=\"utf8\") as f:\r\n",
    "    f.write(\"Id,Predicted\\n\")\r\n",
    "    for qid, label in results:\r\n",
    "        f.write(str(qid[0])+\",\"+str(label)+\"\\n\")"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}